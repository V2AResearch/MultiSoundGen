<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>MultiSoundGen - V2A Demo</title>
  <link rel="stylesheet" href="style.css">
</head>

<body>
  <!-- 导航栏 -->
  <nav>
    <ul>
      <li><a href="#home">Home</a></li>
      <li><a href="#abstract">Abstract</a></li>
      <li><a href="#samples">Samples</a></li>
    </ul>
  </nav>

  <!-- Home 部分 -->
  <section id="home">
    <h1>MultiSoundGen: Video-to-Audio Generation for Multi-Event Scenarios via SlowFast Contrastive Audio-Visual Pretraining and Direct Preference Optimization</h1>
    <p>Welcome to the demo page of MultiSoundGen, a novel V2A model focused on multi-event video-to-audio synthesis.</p>
  </section>

  <!-- Abstract 部分 -->
  <section id="abstract">
    <h2>Abstract</h2>
    <p>
      Current video-to-audio (V2A) methods struggle in complex multi-event scenarios (video scenarios involving multiple sound sources, sound events, or transitions) due to two critical limitations. First, existing methods face challenges in precisely aligning intricate semantic information together with rapid dynamic features. Second, foundational training lacks quantitative prefer-ence optimization for semantic-temporal alignment and audio quality. As a result, it fails to enhance integrated generation qual-ity in cluttered multi-event scenes. To address these core limitations, this study proposes a novel V2A framework: MultiSoundGen. It introduces direct preference optimization (DPO) into the V2A domain, leveraging audio-visual pretraining (AVP) to enhance performance in complex multi-event scenarios. Our contributions include two key innovations: the first is SlowFast Contrastive AVP (SF-CAVP), a pioneering AVP model with a unified dual-stream architecture. SF-CAVP explicitly aligns core semantic representations and rapid dynamic features of audio-visual data to handle multi-event complexity; second, we integrate the DPO method into V2A task and propose AVP-Ranked Preference Optimization (AVP-RPO). It uses SF-CAVP as a reward model to quantify and prioritize critical semantic-temporal matches while enhancing audio quality. Experiments demonstrate that MultiSoundGen achieves state-of-the-art (SOTA) performance in multi-event scenarios, delivering comprehensive gains across distribution matching, audio quality, semantic alignment, and temporal synchronization.
    </p>
    <figure>
      <img src="abstract.jpg" alt="Abstract Figure">
      <figcaption>MultiSoundGen: a novel V2A framework for multi-event scenarios.</figcaption>
    </figure>
  </section>

  <!-- Samples 部分 -->
  <section id="samples">
    <h2>Samples for multi-event V2A</h2>

    <!-- Demo 1 -->
    <div class="demo">
      <h3>Demo 1: Movie scene—an Intense motorcycle chase</h3>
      <div class="video-group">
        <div class="video-item">
          <h4>Ground Truth</h4>
          <video controls>
            <source src="videos/demo1_GT.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <div class="video-item">
          <h4>MultiSoundGen</h4>
          <video controls>
            <source src="videos/demo1_MultiSoundGen.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <div class="video-item">
          <h4>MMAudio</h4>
          <video controls>
            <source src="videos/demo1_MMAudio.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <div class="video-item">
          <h4>FoleyCrafter</h4>
          <video controls>
            <source src="videos/demo1_Folycrafter.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <div class="video-item">
          <h4>Seeing&Hearing</h4>
          <video controls>
            <source src="videos/demo1_Seeing_Hearing.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <div class="video-item">
          <h4>V_AURA</h4>
          <video controls>
            <source src="videos/demo1_V_AURA.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </div>
    </div>

    <!-- Demo 2 -->
    <div class="demo">
      <h3>Demo 2: Unconventional two-person music performance</h3>
      <div class="video-group">
        <div class="video-item">
          <h4>Ground Truth</h4>
          <video controls>
            <source src="videos/demo2_GT.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <div class="video-item">
          <h4>MultiSoundGen</h4>
          <video controls>
            <source src="videos/demo2_MultiSoundGen.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </div>
    </div>

    <!-- Demo 3 -->
    <div class="demo">
      <h3>Demo 3: Two dogs making different types of barking sounds</h3>
      <div class="video-group">
        <div class="video-item">
          <h4>Ground Truth</h4>
          <video controls>
            <source src="videos/demo3_GT.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
        <div class="video-item">
          <h4>MultiSoundGen</h4>
          <video controls>
            <source src="videos/demo3_MultiSoundGen.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </div>
    </div>

    <p class="disclaimer">This is an research demonstration for academic purposes only</p>
  </section>
</body>

</html>